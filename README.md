# üìÄ LangChain, FastAPI, StreamlitÏùÑ Ïù¥Ïö©Ìïú Text-to-SQL

Ïù¥ ÌîÑÎ°úÏ†ùÌä∏Îäî ÏûêÏó∞Ïñ¥ ÏßàÎ¨∏ÏùÑ SQL ÏøºÎ¶¨Î°ú Î≥ÄÌôòÌïòÏó¨ DVD Rental Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§Ïùò Ï†ïÎ≥¥Î•º Ï°∞ÌöåÌïòÎäî Îç∞Î™®ÏûÖÎãàÎã§. ÌïµÏã¨ Î°úÏßÅÏùÄ FastAPI Î∞±ÏóîÎìúÎ°ú, ÏÇ¨Ïö©Ïûê Ïù∏ÌÑ∞ÌéòÏù¥Ïä§Îäî Streamlit ÌîÑÎ°†Ìä∏ÏóîÎìúÎ°ú Íµ¨ÌòÑÎêòÏóàÏäµÎãàÎã§.

## ‚ú® Îç∞Î™® ÎπÑÎîîÏò§ ÎßÅÌÅ¨ 
https://youtu.be/u8IuD13FR7s 

## ‚ú® Ï£ºÏöî Í∏∞Îä•

- **Text-to-SQL**: ÏÇ¨Ïö©ÏûêÏùò ÏßàÎ¨∏ÏùÑ Ïù¥Ìï¥ÌïòÍ≥† SQL ÏøºÎ¶¨Î°ú Î≥ÄÌôòÌï©ÎãàÎã§.
- **Î≤°ÌÑ∞ ÏûÑÎ≤†Îî© Í≤ÄÏÉâ**: OpenAI ÏûÑÎ≤†Îî©Í≥º pgvectorÎ•º ÏÇ¨Ïö©ÌïòÏó¨ Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§ Ïª®ÌÖêÏ∏†Ïóê ÎåÄÌïú ÏùòÎØ∏ Í∏∞Î∞ò Í≤ÄÏÉâÏùÑ ÏàòÌñâÌï©ÎãàÎã§.
- **ÌïòÏù¥Î∏åÎ¶¨Îìú Í≤ÄÏÉâ**: Î≤°ÌÑ∞ Í≤ÄÏÉâÍ≥º Text-to-SQLÏùÑ Í≤∞Ìï©ÌïòÏó¨ Îçî Ï†ïÌôïÌïú ÏøºÎ¶¨Î•º ÏÉùÏÑ±Ìï©ÎãàÎã§.
- **Ïä§ÎßàÌä∏ ÏùòÎèÑ ÌååÏïÖ**: "ÏãúÍ∞ÅÌôî", "Ï∞®Ìä∏", "Í∑∏ÎûòÌîÑ" Îì± Î™ÖÏãúÏ†ÅÏù∏ ÏöîÏ≤≠Ïù¥ ÏûàÏùÑ ÎïåÎßå ÏãúÍ∞ÅÌôîÎ•º ÏàòÌñâÌï©ÎãàÎã§.
- **Îç∞Ïù¥ÌÑ∞ ÏãúÍ∞ÅÌôî**: ÏøºÎ¶¨ Í≤∞Í≥ºÎ•º Í∏∞Î∞òÏúºÎ°ú Ïù∏ÌÑ∞Î†âÌã∞Î∏å Ï∞®Ìä∏(ÎßâÎåÄ, ÏÑ†, Ïõê)Î•º ÏÉùÏÑ±Ìï©ÎãàÎã§.
- **Ï∞®Ìä∏ ÎÇ¥Î≥¥ÎÇ¥Í∏∞**: Ï∞®Ìä∏Î•º JSON ÎòêÎäî CSV ÌååÏùºÎ°ú Ï†ÄÏû•ÌïòÏó¨ Ï∂îÍ∞Ä Î∂ÑÏÑùÏù¥ Í∞ÄÎä•Ìï©ÎãàÎã§.
- **ÏûêÏó∞Ïñ¥ ÎãµÎ≥Ä ÏÉùÏÑ±**: SQL ÏøºÎ¶¨ Í≤∞Í≥ºÎ•º Î∞îÌÉïÏúºÎ°ú ÏûêÏó∞Ïä§Îü¨Ïö¥ Î¨∏Ïû• ÎãµÎ≥ÄÏùÑ ÏÉùÏÑ±Ìï©ÎãàÎã§.
- **Îã§Íµ≠Ïñ¥ ÏßÄÏõê**: ÌïúÍµ≠Ïñ¥ÏôÄ ÏòÅÏñ¥Î°ú ÏßàÎ¨∏ÌïòÍ≥† ÎãµÎ≥ÄÏùÑ Î∞õÏùÑ Ïàò ÏûàÏäµÎãàÎã§.
- **Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§ Ïó∞Îèô**: pgvector ÌôïÏû•Ïù¥ ÏÑ§ÏπòÎêú PostgreSQL Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§Ïóê Ïó∞Í≤∞Ìï©ÎãàÎã§.
- **LangChain ÌÜµÌï©**: LangChainÏùÑ ÌôúÏö©ÌïòÏó¨ Ìö®Ïú®Ï†ÅÏù∏ Text-to-SQL ÌååÏù¥ÌîÑÎùºÏù∏ÏùÑ Íµ¨Ï∂ïÌï©ÎãàÎã§.
- **Î∞±ÏóîÎìú/ÌîÑÎ°†Ìä∏ÏóîÎìú Î∂ÑÎ¶¨**: FastAPI Î∞±ÏóîÎìúÍ∞Ä Î°úÏßÅÏùÑ Ï≤òÎ¶¨ÌïòÍ≥†, Streamlit Ïï±Ïù¥ UIÎ•º Ï†úÍ≥µÌï©ÎãàÎã§.

## üõ†Ô∏è Í∏∞Ïà† Ïä§ÌÉù

- **Ïñ∏Ïñ¥**: Python 3.11
- **Î∞±ÏóîÎìú**: FastAPI
- **ÌîÑÎ°†Ìä∏ÏóîÎìú**: Streamlit
- **ÌïµÏã¨ Î°úÏßÅ**: LangChain
- **Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§**: PostgreSQL with pgvector ÌôïÏû• (DVD Rental ÏÉòÌîå Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§)
- **Î≤°ÌÑ∞ Í≤ÄÏÉâ**: OpenAI Embeddings (text-embedding-3-small) + pgvector
- **LLM**: OpenAI GPT-4-Turbo
- **ÏãúÍ∞ÅÌôî**: Altair
- **ÌïµÏã¨ ÎùºÏù¥Î∏åÎü¨Î¶¨**: `fastapi`, `uvicorn`, `streamlit`, `langchain`, `langchain-openai`, `psycopg2-binary`, `altair`, `pandas`, `pgvector`

## üöÄ ÏãúÏûëÌïòÍ∏∞

### 1. Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§ ÏÑ§Ï†ï

DockerÍ∞Ä ÏÑ§ÏπòÎêòÏñ¥ ÏûàÎã§Î©¥, `dvdrental` ÎîîÎ†âÌÑ∞Î¶¨Ïùò `docker-compose.yml` ÌååÏùºÏùÑ ÏÇ¨Ïö©ÌïòÏó¨ PostgreSQL Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§ ÏÑúÎ≤ÑÎ•º ÏãúÏûëÌï† Ïàò ÏûàÏäµÎãàÎã§.

```bash
# Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§ ÎîîÎ†âÌÑ∞Î¶¨Î°ú Ïù¥Îèô
cd dvdrental

# ÏÑúÎ≤Ñ ÏãúÏûë
docker-compose up -d
```

### 2. Python Í∞ÄÏÉÅ ÌôòÍ≤Ω ÏÑ§Ï†ï

ÌîÑÎ°úÏ†ùÌä∏ Î£®Ìä∏ ÎîîÎ†âÌÑ∞Î¶¨ÏóêÏÑú Python Í∞ÄÏÉÅ ÌôòÍ≤ΩÏùÑ ÏÉùÏÑ±ÌïòÍ≥† ÌôúÏÑ±ÌôîÌï©ÎãàÎã§.

```bash
# Í∞ÄÏÉÅ ÌôòÍ≤Ω ÏÉùÏÑ± (Python 3.11 Í∏∞Ï§Ä)
python -m venv venv

# Í∞ÄÏÉÅ ÌôòÍ≤Ω ÌôúÏÑ±Ìôî (Windows PowerShell)
.\venv\Scripts\Activate.ps1

# Í∞ÄÏÉÅ ÌôòÍ≤Ω ÌôúÏÑ±Ìôî (macOS/Linux)
source venv/bin/activate
```

### 3. ÏùòÏ°¥ÏÑ± ÏÑ§Ïπò

ÌïÑÏöîÌïú Python ÎùºÏù¥Î∏åÎü¨Î¶¨Î•º ÏÑ§ÏπòÌï©ÎãàÎã§.

```bash
pip install -r requirements.txt
```

### 4. ÌôòÍ≤Ω Î≥ÄÏàò ÏÑ§Ï†ï

ÌîÑÎ°úÏ†ùÌä∏ Î£®Ìä∏ ÎîîÎ†âÌÑ∞Î¶¨(`mungyu_version_query_vending_machine`)Ïóê `.env` ÌååÏùºÏùÑ ÏÉùÏÑ±ÌïòÍ≥†, Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§ Ï†ïÎ≥¥ÏôÄ OpenAI API ÌÇ§Î•º ÏûÖÎ†•Ìï©ÎãàÎã§.

```
DB_USER=your_db_user
DB_PASSWORD=your_db_password
DB_HOST=your_db_host
DB_PORT=your_db_port
DB_NAME=your_db_name
OPENAI_API_KEY=your_openai_api_key
```

### 5. Î≤°ÌÑ∞ ÏûÑÎ≤†Îî© ÏÉùÏÑ± (ÏµúÏ¥à 1ÌöåÎßå)

Ïï†ÌîåÎ¶¨ÏºÄÏù¥ÏÖòÏùÑ Ï≤òÏùå Ïã§ÌñâÌïòÍ∏∞ Ï†ÑÏóê Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§ Ïª®ÌÖêÏ∏†Ïóê ÎåÄÌïú Î≤°ÌÑ∞ ÏûÑÎ≤†Îî©ÏùÑ ÏÉùÏÑ±Ìï©ÎãàÎã§:

```bash
# Í∞ÄÏÉÅ ÌôòÍ≤ΩÏù¥ ÌôúÏÑ±ÌôîÎêòÏóàÎäîÏßÄ ÌôïÏù∏ÌïòÏÑ∏Ïöî.
python -m app.embeddings
```

Ïù¥ Î™ÖÎ†πÏùÄ:
- ÏòÅÌôî, Î∞∞Ïö∞, Í≥†Í∞ù, Ïπ¥ÌÖåÍ≥†Î¶¨Ïóê ÎåÄÌïú ÏûÑÎ≤†Îî©ÏùÑ ÏÉùÏÑ±Ìï©ÎãàÎã§
- pgvectorÎ•º ÏÇ¨Ïö©ÌïòÏó¨ PostgreSQL Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§Ïóê Ï†ÄÏû•Ìï©ÎãàÎã§
- ÌïòÏù¥Î∏åÎ¶¨Îìú Í≤ÄÏÉâÏùÑ ÏúÑÌïú ÌÜµÌï© ÏûÑÎ≤†Îî© ÌÖåÏù¥Î∏îÏùÑ ÏÉùÏÑ±Ìï©ÎãàÎã§
- ÏïΩ 1-2Î∂Ñ ÏÜåÏöîÎêòÎ©∞ OpenAI API ÏÇ¨Ïö©Î£åÎäî ÏïΩ $0.01-0.05ÏûÖÎãàÎã§

### 6. Ïï†ÌîåÎ¶¨ÏºÄÏù¥ÏÖò Ïã§Ìñâ

`mungyu_version_query_vending_machine` ÎîîÎ†âÌÑ∞Î¶¨ÏóêÏÑú Îëê Í∞úÏùò ÌÑ∞ÎØ∏ÎÑêÏùÑ Ïó¥Í≥† Í∞ÅÍ∞Å Îã§Ïùå Î™ÖÎ†πÏùÑ Ïã§ÌñâÌï¥Ïïº Ìï©ÎãàÎã§.

**ÌÑ∞ÎØ∏ÎÑê 1: FastAPI Î∞±ÏóîÎìú ÏãúÏûë**

```bash
# Í∞ÄÏÉÅ ÌôòÍ≤ΩÏù¥ ÌôúÏÑ±ÌôîÎêòÏóàÎäîÏßÄ ÌôïÏù∏ÌïòÏÑ∏Ïöî.
.\venv\Scripts\python.exe -m uvicorn app.main:app --host 127.0.0.1 --port 8000 --reload
```

**ÌÑ∞ÎØ∏ÎÑê 2: Streamlit ÌîÑÎ°†Ìä∏ÏóîÎìú ÏãúÏûë**

```bash
# Í∞ÄÏÉÅ ÌôòÍ≤ΩÏù¥ ÌôúÏÑ±ÌôîÎêòÏóàÎäîÏßÄ ÌôïÏù∏ÌïòÏÑ∏Ïöî.
streamlit run streamlit_app.py
```

Ïù¥Ï†ú Ïõπ Î∏åÎùºÏö∞Ï†ÄÎ•º Ïó¥Í≥† StreamlitÏù¥ Ï†úÍ≥µÌïòÎäî Î°úÏª¨ URL(Ïòà: `http://localhost:8501`)Î°ú Ï†ëÏÜçÌïòÏÑ∏Ïöî.

---

# üìÄ Text-to-SQL with LangChain, FastAPI, and Streamlit

This is a demo project that converts natural language questions into SQL queries to retrieve information from the DVD Rental database. It uses a FastAPI backend for the core logic and a Streamlit frontend for the user interface.

## ‚ú® Demo Video Link
https://youtu.be/u8IuD13FR7s 

## ‚ú® Features

- **Natural Language to SQL**: Understands user questions and converts them into SQL queries.
- **Vector Embedding Search**: Uses OpenAI embeddings and pgvector for semantic search across database content.
- **Hybrid Search**: Combines vector search with Text-to-SQL for more accurate query generation.
- **Smart Intent Recognition**: Detects visualization requests only when explicitly mentioned (e.g., "visualize", "chart", "graph").
- **Data Visualization**: Generates interactive charts (bar, line, pie) based on query results.
- **Chart Export**: Save charts as JSON or CSV files for further analysis.
- **Natural Language Response**: Generates a natural language answer based on the SQL query results.
- **Multilingual Support**: Supports both Korean and English for questions and responses.
- **Database Integration**: Connects to a PostgreSQL database with pgvector extension.
- **LangChain Integration**: Utilizes LangChain to build an efficient Text-to-SQL pipeline.
- **Separated Backend/Frontend**: A FastAPI backend handles the logic, while a Streamlit app provides the UI.

## Workflow

```mermaid
sequenceDiagram
    participant User
    participant Streamlit UI
    participant FastAPI Backend
    participant Vector Search
    participant LangChain Chain
    participant OpenAI
    participant PostgreSQL DB

    User->>Streamlit UI: 1. Enter question (Korean/English)
    Streamlit UI->>FastAPI Backend: 2. Send question + language via API
    
    Note over FastAPI Backend,Vector Search: Hybrid Search
    FastAPI Backend->>Vector Search: 3. Perform semantic search
    Vector Search->>PostgreSQL DB: 4. Query vector embeddings (pgvector)
    PostgreSQL DB-->>Vector Search: 5. Return similar content
    Vector Search-->>FastAPI Backend: 6. Return relevant context
    
    FastAPI Backend->>LangChain Chain: 7. Invoke chain with question + context
    
    Note over LangChain Chain,OpenAI: Intent Recognition
    LangChain Chain->>OpenAI: 8. Analyze intent (explicit visualization?)
    OpenAI-->>LangChain Chain: 9. Return intent + chart type
    
    Note over LangChain Chain,OpenAI: SQL Generation
    LangChain Chain->>OpenAI: 10. Generate SQL Query (with context)
    OpenAI-->>LangChain Chain: 11. Return SQL Query
    
    Note over LangChain Chain,PostgreSQL DB: Query Execution
    LangChain Chain->>PostgreSQL DB: 12. Execute SQL Query
    PostgreSQL DB-->>LangChain Chain: 13. Return SQL Result
    
    Note over LangChain Chain,OpenAI: Response Generation
    LangChain Chain->>OpenAI: 14. Generate NL answer + chart data
    OpenAI-->>LangChain Chain: 15. Return answer + chart data
    
    LangChain Chain-->>FastAPI Backend: 16. Return all results
    FastAPI Backend-->>Streamlit UI: 17. Send response (SQL, Result, Answer, Chart)
    Streamlit UI->>User: 18. Display results + visualization + export options
```

## üõ†Ô∏è Tech Stack

- **Language**: Python 3.11
- **Backend**: FastAPI
- **Frontend**: Streamlit
- **Core Logic**: LangChain
- **Database**: PostgreSQL with pgvector extension (DVD Rental Sample Database)
- **Vector Search**: OpenAI Embeddings (text-embedding-3-small) + pgvector
- **LLM**: OpenAI GPT-4-Turbo
- **Visualization**: Altair
- **Key Libraries**: `fastapi`, `uvicorn`, `streamlit`, `langchain`, `langchain-openai`, `psycopg2-binary`, `altair`, `pandas`, `pgvector`

## üöÄ Getting Started

### 1. Set up the Database

If you have Docker, you can start the PostgreSQL database server using the provided `docker-compose.yml` in the `dvdrental` directory.

```bash
# Navigate to the database directory
cd dvdrental

# Start the server
docker-compose up -d
```

### 2. Set up Python Virtual Environment

From the project root directory, create and activate a Python virtual environment.

```bash
# Create a virtual environment (for Python 3.11)
python -m venv venv

# Activate the virtual environment (Windows PowerShell)
.\venv\Scripts\Activate.ps1

# Activate the virtual environment (macOS/Linux)
source venv/bin/activate
```

### 3. Install Dependencies

Install the required Python libraries.

```bash
pip install -r requirements.txt
```

### 4. Set up Environment Variables

Create a `.env` file in the project root directory (`mungyu_version_query_vending_machine`) and add your database credentials and OpenAI API key.

```
DB_USER=your_db_user
DB_PASSWORD=your_db_password
DB_HOST=your_db_host
DB_PORT=your_db_port
DB_NAME=your_db_name
OPENAI_API_KEY=your_openai_api_key
```

### 5. Generate Vector Embeddings (First Time Only)

Before running the application for the first time, generate vector embeddings for the database content:

```bash
# Make sure your virtual environment is activated
python -m app.embeddings
```

This will:
- Generate embeddings for films, actors, customers, and categories
- Store them in the PostgreSQL database with pgvector
- Create a unified embeddings table for hybrid search
- Takes approximately 1-2 minutes and costs ~$0.01-0.05 in OpenAI API usage

### 6. Run the Application

You need to run two processes in separate terminals from the `mungyu_version_query_vending_machine` directory.

**Terminal 1: Start the FastAPI Backend**

```bash
# Make sure your virtual environment is activated
.\venv\Scripts\python.exe -m uvicorn app.main:app --host 127.0.0.1 --port 8000 --reload
```

**Terminal 2: Start the Streamlit Frontend**

```bash
# Make sure your virtual environment is activated
streamlit run streamlit_app.py
```

Now, open your web browser and go to the local URL provided by Streamlit (e.g., `http://localhost:8501`).
