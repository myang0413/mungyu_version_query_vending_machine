from sqlalchemy import create_engine, text
from dotenv import load_dotenv
from openai import OpenAI
import streamlit as st
import pandas as pd
import os

# .env íŒŒì¼ì˜ ì ˆëŒ€ ê²½ë¡œë¥¼ ì§€ì •í•˜ì—¬ í™˜ê²½ ë³€ìˆ˜ ë¶ˆëŸ¬ì˜¤ê¸°
from pathlib import Path

# __file__ì€ í˜„ì¬ ì‹¤í–‰ ì¤‘ì¸ ìŠ¤í¬ë¦½íŠ¸ì˜ ê²½ë¡œë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.
# .parentë¥¼ ì‚¬ìš©í•˜ì—¬ í•´ë‹¹ íŒŒì¼ì´ ì†í•œ ë””ë ‰í„°ë¦¬ë¥¼ ì–»ìŠµë‹ˆë‹¤.
# ì´ë¥¼ í†µí•´ í•­ìƒ main.pyì™€ ë™ì¼í•œ ìœ„ì¹˜ì— ìˆëŠ” .env íŒŒì¼ì„ ì°¾ìŠµë‹ˆë‹¤.
env_path = Path(__file__).parent / '.env'
load_dotenv(dotenv_path=env_path)

# db
# .env íŒŒì¼ ë¡œë”©ì— ì‹¤íŒ¨í•  ê²½ìš°ë¥¼ ëŒ€ë¹„í•˜ì—¬ docker-compose.ymlê³¼ ì¼ì¹˜í•˜ëŠ” ê¸°ë³¸ê°’ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
DB_USER = os.getenv("DB_USER", "postgres")
DB_PASS = os.getenv("DB_PASS", "password")
DB_HOST = os.getenv("DB_HOST", "localhost")
DB_PORT = os.getenv("DB_PORT", "5433")
DB_NAME = os.getenv("DB_NAME", "dvdrental")
DB_URL = f"postgresql+psycopg2://{DB_USER}:{DB_PASS}@{DB_HOST}:{DB_PORT}/{DB_NAME}"
engine = create_engine(DB_URL, echo=True, future=True)

# external api
API_KEY = os.getenv("OPENAI_API_KEY") # ê°œì¸ api í‚¤
client = OpenAI(api_key=API_KEY)

# argument - í™˜ê²½ë³€ìˆ˜ë¡œ ì´ˆê¸°í™” ì—¬ë¶€ í™•ì¸
INIT_TABLE_DOCS = os.getenv("INIT_TABLE_DOCS", "0") == "1"

def run_query(query: str, params: dict = None):
    with engine.connect() as conn:
        result = conn.execute(text(query), params or {})
        return [dict(row._mapping) for row in result]

def run_command(query: str, params: dict = None):
    with engine.begin() as conn:
        conn.execute(text(query), params or {})

def get_embedding(text:str, model:str="text-embedding-3-small") -> list[float]:
    # dims: 1536
    response = client.embeddings.create(
        input=text,
        model=model
    )
    embedding = response.data[0].embedding
    return embedding

def extract_ddl(table_name):
    ddl_query = f"""SELECT 
        column_name, 
        data_type,
        is_nullable,
        column_default
    FROM 
        information_schema.columns
    WHERE 
        table_schema = 'public' AND table_name = '{table_name}';"""
    
    result = run_query(ddl_query)

    column_dict = {
        # âœ… ìˆ˜ì •: ë¦¬ìŠ¤íŠ¸ ["column_name"] ëŒ€ì‹  v["column_name"] (ë¬¸ìì—´ ê°’) ì‚¬ìš©
        v["column_name"]:{ 
            "data_type": v["data_type"],
            "is_nullable": v["is_nullable"],
            "column_default": v["column_default"]
        } for v in result
    }

    return column_dict

def make_table_desc_dict():
    # dvdrental ì† í…Œì´ë¸”ë“¤ì— ëŒ€í•œ ê°„ë‹¨í•œ ì„¤ëª…ì„ ì‘ì„±í•œ ë©”íƒ€ ì •ë³´.
    table_desc_dict = { 
        "actor": "contains actors data including first name and last name.",
        "film": "contains films data such as title, release year, length, rating, etc.",
        "film_actor": "contains the relationships between films and actors.",
        "category": "contains filmâ€™s categories data.",
        "film_category": "containing the relationships between films and categories.",
        "store": "contains the store data including manager staff and address.",
        "inventory": "stores inventory data.",
        "rental": "stores rental data.",
        "payment": "stores customerâ€™s payments.",
        "staff": "stores staff data.",
        "customer": "stores customerâ€™s data.",
        "address": "stores address data for staff and customers.",
        "city": "stores the city names.",
        "country": "stores the country names."
    }
    return table_desc_dict
    
def insert_doc(name: str):
    """í…Œì´ë¸”ëª…, DDL, ì§§ì€ ì„¤ëª…ì„ í•©ì³ì„œ í•˜ë‚˜ì˜ ë¬¸ì„œë¡œ ì €ì¥"""
    # ì„¤ëª… + DDL í•©ì¹˜ê¸°
    table_desc_dict = make_table_desc_dict()
    ddl = extract_ddl(name)
    summary = table_desc_dict[name]
    
    doc_text = f"""
    <Description>
    
    {summary}
    
    </Description>



    <DDL>
    
    {ddl}
    
    </DDL>
    
    """
    embedding = get_embedding(doc_text)

    run_command(
        """
        INSERT INTO table_docs (name, description, embedding)
        VALUES (:name, :description, :embedding)
        """,
        {"name": name, "description": doc_text, "embedding": embedding}
    )
    

def create_table_docs_if_not_exists():
    """'table_docs' í…Œì´ë¸”ì´ ì¡´ì¬í•˜ì§€ ì•Šìœ¼ë©´ ìƒì„±í•©ë‹ˆë‹¤."""
    # pg_vector í™•ì¥ì´ í™œì„±í™”ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ê³ , ì—†ìœ¼ë©´ ìƒì„±
    run_command("CREATE EXTENSION IF NOT EXISTS vector;")
    # table_docs í…Œì´ë¸”ì´ ì—†ìœ¼ë©´ ìƒì„±
    run_command("""
        CREATE TABLE IF NOT EXISTS table_docs (
            id SERIAL PRIMARY KEY,
            name TEXT NOT NULL,
            description TEXT,
            embedding VECTOR(1536)
        );
    """)

def initialize_table_docs():
    """'table_docs' í…Œì´ë¸”ì´ ë¹„ì–´ ìˆìœ¼ë©´ ëª¨ë“  í…Œì´ë¸”ì˜ ë¬¸ì„œì™€ ì„ë² ë”©ì„ ì±„ì›ë‹ˆë‹¤."""
    create_table_docs_if_not_exists()
    
    # í…Œì´ë¸”ì´ ë¹„ì–´ ìˆëŠ”ì§€ í™•ì¸
    count_result = run_query("SELECT COUNT(*) as count FROM table_docs")
    if count_result[0]['count'] == 0:
        st.info("Table documents not found. Initializing... Please wait.")
        print("Initializing table documents and embeddings...")
        
        progress_bar = st.progress(0)
        tables = list(make_table_desc_dict().keys())
        total_tables = len(tables)

        for i, table_name in enumerate(tables):
            try:
                insert_doc(table_name)
                progress_bar.progress((i + 1) / total_tables, text=f"Processing {table_name}...")
            except Exception as e:
                st.error(f"Error processing table {table_name}: {e}")
                print(f"Error processing table {table_name}: {e}")
        
        st.success("Initialization complete!")
        st.balloons()
        print("Initialization complete.")
    else:
        print("Table documents are already initialized.")

# ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹œì‘ ì‹œ í…Œì´ë¸” ë¬¸ì„œ ì´ˆê¸°í™” ì‹¤í–‰
initialize_table_docs()


def search_docs(query: str, limit: int = 1):
    # ì§ˆì˜ â†’ ìœ ì‚¬ ë¬¸ì„œ ê²€ìƒ‰
    query_emb = get_embedding(query)
    sql = """
        SELECT id, name, description,
               embedding <=> (:query_emb)::vector AS distance
        FROM table_docs
        ORDER BY embedding <=> (:query_emb)::vector
        LIMIT :limit;
    """
    return run_query(sql, {"query_emb": query_emb, "limit": limit})

def clean_sql_output(raw: str) -> str:
    import re
    return re.sub(r"^```sql\n|\n```$", "", raw.strip())

def generate_sql(natural_query: str, limit: int = 2):
    # 1. ìœ ì‚¬ í…Œì´ë¸” ê²€ìƒ‰
    results = search_docs(natural_query, limit=limit)
    name = results[0]["name"] if results else ""
    context = results[0]["description"] if results else ""

    # 2. LLM í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    system_prompt = """You are an expert SQL generator.
    
    You will be given:
    1. A natural language query from the user.
    2. A context object where each key is a table name and its value is text that includes:
       - A <Description> ... </Description> block: short natural language description of the table.
       - A <DDL> ... </DDL> block: the schema of that table, with column names, data types, and constraints.
    
    Your task:
    - Generate a valid SQL query that answers the natural language query.
    - Use only the provided tables and columns.
    - Do not invent tables or columns that are not in the context.
    - Return only the SQL query, nothing else.
    """

    
    user_prompt = f"""

    <name>
    the name of the table is `{name}` .
    </name>

    <Question>
    {natural_query}
    </Question>


    <Context>
    {context}
    </Context>
    
    """

    # 3. OpenAI í˜¸ì¶œ
    resp = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt},
        ],
        temperature=0.5,
        max_completion_tokens=300,
    )
    print("-------")
    print(user_prompt)
    print("-------")
    
    sql_query = resp.choices[0].message.content
    return clean_sql_output(sql_query)

if __name__ == "__main__":
    st.title("ğŸ“ Text2SQL Demo")

    natural_query = st.text_input("Enter your question:", "List the title and release year of movies.")

    if st.button("Run"):
        with st.spinner('Generating SQL...'):
            query = generate_sql(natural_query)
        
        st.subheader("Generated SQL Query")
        st.code(query, language="sql")

        try:
            rows = run_query(query)
            df = pd.DataFrame(rows)
            st.dataframe(df)
        except Exception as e:
            st.error(f"Error running query: {e}")